{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in c:\\users\\91808\\downloads\\insurance\\myenv\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\91808\\downloads\\insurance\\myenv\\lib\\site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\91808\\downloads\\insurance\\myenv\\lib\\site-packages (from gdown) (3.13.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\91808\\downloads\\insurance\\myenv\\lib\\site-packages (from gdown) (4.66.2)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\91808\\downloads\\insurance\\myenv\\lib\\site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\91808\\downloads\\insurance\\myenv\\lib\\site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91808\\downloads\\insurance\\myenv\\lib\\site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91808\\downloads\\insurance\\myenv\\lib\\site-packages (from requests[socks]->gdown) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91808\\downloads\\insurance\\myenv\\lib\\site-packages (from requests[socks]->gdown) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91808\\downloads\\insurance\\myenv\\lib\\site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\91808\\downloads\\insurance\\myenv\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\91808\\downloads\\insurance\\myenv\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gdown\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\91808\\\\Downloads\\\\Insurance\\\\notebook'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\91808\\\\Downloads\\\\Insurance'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?/export=download&id=1fcpUvif1mxJ7vBASIVR_oro1g1LupPEB\n",
      "To: c:\\Users\\91808\\Downloads\\Insurance\\artifact\\04232024__142817\\data_ingestion\\data.zip\n",
      "100%|██████████| 13.4k/13.4k [00:00<00:00, 4.46MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91808\\Downloads\\Insurance\\artifact\\04232024__142817\\data_ingestion\\feature_store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from InsurancePremium.entity.config_entity import DataIngestionConfig,TrainingPipelineConfig\n",
    "from InsurancePremium.constants.training_pipeline import *\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from InsurancePremium.constants.training_pipeline import *\n",
    "from InsurancePremium.exception import CustomException\n",
    "from InsurancePremium.logger.logging import logging\n",
    "import sys\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self,data_ingestion_config:DataIngestionConfig):\n",
    "        try:\n",
    "       \n",
    "            self.data_ingestion_config=data_ingestion_config\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def download_data(self):\n",
    "        logging.info(\"Entered the download_data method\")\n",
    "\n",
    "        try:\n",
    "            data_url=self.data_ingestion_config.data_download_url\n",
    "            logging.info(\"got the data url\")\n",
    "            data_download_dir=self.data_ingestion_config.data_ingestion_dir\n",
    "            zip_file_name=self.data_ingestion_config.data_file_name\n",
    "            os.makedirs(data_download_dir, exist_ok=True)\n",
    "            logging.info(\"created the data download directory\")\n",
    "            file_id=data_url.split(\"/\")[-2]\n",
    "            pre=self.data_ingestion_config.prefix\n",
    "            data_file=f\"{data_download_dir}/{zip_file_name}\"\n",
    "            logging.info(f\"downloading the data from {data_url} to {data_download_dir}\")\n",
    "            gdown.download(pre+file_id,data_file)\n",
    "            logging.info(\"data download successful\")\n",
    "            feature_store=self.data_ingestion_config.feature_store_file_path\n",
    "            print(feature_store)\n",
    "            os.makedirs(feature_store,exist_ok=True)\n",
    "            logging.info(\"extracting  the data from zip file\")\n",
    "            with zipfile.ZipFile(data_file,\"r\") as file:\n",
    "                data=file.extractall(feature_store)\n",
    "                logging.info(\"data extracted\")\n",
    "                \n",
    "            df=pd.read_csv(f\"{feature_store}/insurance.csv\")\n",
    "            \n",
    "            train_df,test_df=train_test_split(df,test_size=self.data_ingestion_config.test_size\n",
    "                                              ,random_state=42)\n",
    "            logging.info(\"Data divided into train and test\")\n",
    "            data_dir=self.data_ingestion_config.data_set_dir\n",
    "            os.makedirs(data_dir,exist_ok=True)\n",
    "\n",
    "            train_df.to_csv(self.data_ingestion_config.train_file_path,index=False,header=True)\n",
    "            test_df.to_csv(self.data_ingestion_config.test_file_path,index=False,header=True)\n",
    "            logging.info(\"got the train.csv and test.csv file successfully\")\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "\n",
    "data_pipeline_config=TrainingPipelineConfig()\n",
    "data_ingestion_config=DataIngestionConfig(data_pipeline_config)\n",
    "obj=DataIngestion(data_ingestion_config=data_ingestion_config)\n",
    "zip_file=obj.download_data()\n",
    "# obj.unzip_data(zip_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InsurancePremium.entity.config_entity import TrainingPipelineConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_training_pipeline():\n",
    "    try:\n",
    "        training_pipeline_config=TrainingPipelineConfig()\n",
    "        data_ingestion_config  =DataIngestionConfig(training_pipeline_config=training_pipeline_config)\n",
    "        # print(data_ingestion_config)\n",
    "        data_ingestion = DataIngestion(data_ingestion_config=data_ingestion_config)\n",
    "        data_ingestion_artifact = data_ingestion.download_data()\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?/export=download&id=1fcpUvif1mxJ7vBASIVR_oro1g1LupPEB\n",
      "To: c:\\Users\\91808\\Downloads\\Insurance\\artifact\\04232024__142820\\data_ingestion\\data.zip\n",
      "100%|██████████| 13.4k/13.4k [00:00<00:00, 6.70MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91808\\Downloads\\Insurance\\artifact\\04232024__142820\\data_ingestion\\feature_store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "obj=start_training_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'download_url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m file_id\u001b[38;5;241m=\u001b[39m\u001b[43mdownload_url\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      2\u001b[0m file_id\n",
      "\u001b[1;31mNameError\u001b[0m: name 'download_url' is not defined"
     ]
    }
   ],
   "source": [
    "file_id=download_url.split(\"/\")[-2]\n",
    "file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix=\"https://drive.google.com/uc?/export=download&id=\"\n",
    "\n",
    "gdown.download(prefix+file_id,\"data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(r\"C:\\Users\\91808\\Downloads\\Insurance\\data.zip\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(r\"C:\\Users\\91808\\Downloads\\Insurance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_URl=\"https://drive.google.com/file/d/1fcpUvif1mxJ7vBASIVR_oro1g1LupPEB/view?usp=sharing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown,os,zipfile\n",
    "\n",
    "\n",
    "def download_data(url_path):\n",
    "    download_url=url_path\n",
    "    download_dir=\"artifacts\"\n",
    "    os.makedirs(download_dir,exist_ok=True)\n",
    "    file_id=download_url.split(\"/\")[-2]\n",
    "\n",
    "    prefix=\"https://drive.google.com/uc?/export=download&id=\"\n",
    "    data_file=f\"{download_dir}/data.zip\"\n",
    "    gdown.download(prefix+file_id,data_file)\n",
    "    return data_file\n",
    "    print(data_file)\n",
    "def unzip_data(zip_file_path):\n",
    "    zip_dir=r\"C:\\Users\\91808\\Downloads\\Insurance\\notebook\\artifacts\"\n",
    "    with zipfile.ZipFile(zip_file_path,\"r\") as f:\n",
    "        f.extractall(zip_dir)\n",
    "obj=download_data(r\"https://drive.google.com/file/d/1fcpUvif1mxJ7vBASIVR_oro1g1LupPEB/view?usp=sharing\")\n",
    "data=unzip_data(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InsurancePremium.entity.config_entity import DataIngestionConfig\n",
    "from InsurancePremium.constants.training_pipeline import *\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from InsurancePremium.constants.training_pipeline import *\n",
    "class DataIngestion:\n",
    "    def __init__(self,data_ingestion_config:DataIngestionConfig=DataIngestionConfig):\n",
    "        try:\n",
    "       \n",
    "            self.data_ingestion_config=data_ingestion_config\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "\n",
    "\n",
    "    def download_data(self):\n",
    "        data_set_url=self.data_ingestion_config.data_download_url\n",
    "\n",
    "        file_id=data_set_url.split(\"/\")[-2]\n",
    "        download_dir=self.data_ingestion_config.data_ingestion_dir\n",
    "        zip_download_file=self.data_ingestion_config.local_data_file_path\n",
    "        os.makedirs(download_dir,exist_ok=True)\n",
    "        \n",
    "        prefix=\"https://drive.google.com/uc?/export=download&id=\"\n",
    "   \n",
    "   \n",
    "        gdown.download(prefix+file_id,zip_download_file)\n",
    "        return zip_download_file\n",
    "        \n",
    "    def unzip_data(self,zip_file):\n",
    "        feture_store=self.data_ingestion_config.feature_store_file_path\n",
    "        os.makedirs(feture_store,exist_ok=True)\n",
    "        print(feture_store)\n",
    "       \n",
    "        with zipfile.ZipFile(zip_file,\"r\") as zip_file:\n",
    "            file=zip_file.extractall(feture_store)\n",
    "            print(file)\n",
    "        data=f\"{self.data_ingestion_config.feature_store_file_path}/insurance.csv\"\n",
    "        data_path=pd.read_csv(data)\n",
    "     \n",
    "        \n",
    "        train_df,test_df=train_test_split(data_path\n",
    "                                              ,test_size=0.2,\n",
    "                                             random_state=42)\n",
    "    \n",
    "       \n",
    "\n",
    "        # print(f\"test_df shape is {test_df.shape}\")\n",
    "        # train=self.data_ingestion_config.train_file_path\n",
    "        # test=self.data_ingestion_config.test_file_path\n",
    "        # # train_df.to_csv(f\"{feture_store}/train.csv\",index=False)\n",
    "        # # test_df.to_csv(f\"{feture_store}/test.csv\",index=False)\n",
    "        # train_df.to_csv(feture_store/train,index=False)\n",
    "        # test_df.to_csv(feture_store/test,index=False)\n",
    "            \n",
    "         \n",
    "            \n",
    "\n",
    "obj=DataIngestion()\n",
    "zip=obj.download_data()\n",
    "file=obj.unzip_data(zip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
